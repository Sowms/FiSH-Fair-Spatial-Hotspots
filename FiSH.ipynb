{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FiSH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fairness in Hotspot Detection**\n",
        "\n",
        "This code takes (a) spatial file with sensitive attributes and (b) hotspot file from SaTScan as input\n",
        "\n",
        "The output is a list of fair hotspots"
      ],
      "metadata": {
        "id": "yiaLz0Wz56eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#caste heterogenous \n",
        "\n",
        "#get_total_caste_distribution\n",
        "\n",
        "#parsing SaTScan output file\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def get_clusters(filename):\n",
        "\tf1 = open(filename, \"r\")\n",
        "\tres_lines = f1.readlines()\n",
        "\tf1.close()\n",
        "\tclusters = []\n",
        "\t\n",
        "\tids = []\n",
        "\tflag = False\n",
        "\tfor l in res_lines:\n",
        "\t\tif ('Coordinates' in l):\n",
        "\t\t\tflag = False\n",
        "\t\t\tif (len(ids) != 0):\n",
        "\t\t\t\tclusters.append(ids)\n",
        "\t\t\tids = []\n",
        "\t\t\t\n",
        "\t\tif (flag or 'Location IDs' in l):\n",
        "\t\t\ttemp = l\n",
        "\t\t\ttemp = temp[2:]\n",
        "\t\t\ttemp = temp.replace('Location IDs included.: ', '')\n",
        "\t\t\ttemp = temp.replace(',\\n','').split(', ')\n",
        "\n",
        "\t\t\tfor i in range(0, len(temp)):\n",
        "\t\t\t\ttemp[i] = temp[i].strip()\n",
        "\t\t\tids.extend(temp)\n",
        "\n",
        "\t\tif ('Location IDs' in l):\t\n",
        "\t\t\tflag = True\n",
        "\treturn clusters\n",
        "\n",
        "k = 20 #top-k\n",
        "clusters = get_clusters('result-med-50-new.txt') #SaTScan output file\n",
        "print(clusters)\n",
        "print(len(clusters))\n",
        "clusters = clusters[:k] \n",
        "\n",
        "print(len(clusters))\n",
        "print(clusters)"
      ],
      "metadata": {
        "id": "RPL_-YRK7i-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG37kl4D55tP"
      },
      "outputs": [],
      "source": [
        "#developing caste and religion distribution from dataset\n",
        "caste_df = pd.read_csv('caste_and_religion_info_income.csv')\n",
        "print(caste_df)\n",
        "nf_tot = len(caste_df)\n",
        "n1 = len(caste_df[caste_df.ID13.astype(int).isin([4,5,6])])\n",
        "n2 = len(caste_df[caste_df.ID11.astype(int).isin([2,3,4,5,6,7,8,9])])\n",
        "total = [n1/nf_tot, n2/nf_tot]\n",
        "print(total)  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#modules for computing distance between distributions\n",
        "\n",
        "from scipy.stats import wasserstein_distance\n",
        "\n",
        "def get_sum(region=''):\n",
        "  flag = False\n",
        "  ans = [0]\n",
        "  if (region == ''):\n",
        "    return ans\n",
        "  if (len(region) == 0):\n",
        "    return ans\n",
        "  nf_tot = float(len(region))\n",
        "  if (nf_tot == 0):\n",
        "    return ans\n",
        "  n1 = len(caste_df[caste_df.IDPERSON.astype(str).isin(region) & caste_df.ID13.astype(int).isin([4,5,6])])\n",
        "  n2 = len(caste_df[caste_df.IDPERSON.astype(str).isin(region) & caste_df.ID11.astype(int).isin([2,3,4,5,6,7,8,9])])\n",
        "  ans = [n1/nf_tot, n2/nf_tot]\n",
        "  return ans\n",
        "\n",
        "def div(cluster, total):\n",
        "\treturn wasserstein_distance(total, cluster)\n",
        " \n",
        "print(get_sum(clusters[0]))\n",
        "print(div(get_sum(clusters[0]), total))\n"
      ],
      "metadata": {
        "id": "1briXGGJ9fEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FiSH Algo\n",
        "\n",
        "from ast import literal_eval\n",
        "from random import randrange\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "\n",
        "#beam\n",
        "beam_width = 5 #b in the paper\n",
        "k = 5\n",
        "l = 0\n",
        "n = 20 #k in the paper\n",
        "tau = 5 \n",
        "d = n * (n+1) / 2\n",
        "\n",
        "def sort_beam(x):\n",
        "  new_x = {}\n",
        "  arr = list(x.values())\n",
        "  i = 0\n",
        "  for key, value in x.items():\n",
        "    flag = False\n",
        "    for j in range(0, len(arr)):\n",
        "      if (i == j):\n",
        "        continue\n",
        "      if ((arr[i][0] >= arr[j][0]) and (arr[i][1] >= arr[j][1])):\n",
        "        flag = True\n",
        "        break\n",
        "    if (not flag):\n",
        "      new_x[key] = value\n",
        "    i += 1\n",
        "  val_beam = {}\n",
        "  for key in x.keys():\n",
        "    val = x[key][0]\n",
        "    val_beam[key] = val\n",
        "  val_beam = {k: v for k, v in sorted(val_beam.items(), key=lambda item: item[1])}\n",
        "  final_beam = {}\n",
        "  for key in val_beam.keys():\n",
        "    if (key in new_x):\n",
        "      final_beam[key] = new_x[key]\n",
        "  return final_beam\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_region(areas):\n",
        "  region = []\n",
        "  for area in areas:\n",
        "    region.extend(clusters[area])\n",
        "  return get_sum(region)\n",
        "  \n",
        "\n",
        "beam = {}\n",
        "\n",
        "start = time.time()\n",
        "regions = []\n",
        "begin = div(get_sum(regions), total) \n",
        "for i in range(0, len(clusters)):\n",
        "  region = get_region([i])\n",
        "  delta = div(region, total)\n",
        "  vec = [i, delta]\n",
        "  val = i + l * delta\n",
        "  a = []\n",
        "  a.append(i)  \n",
        "  beam[str(a)] = vec\n",
        "print(beam)\n",
        "#sort\n",
        "beam = sort_beam(beam)\n",
        "print(beam)\n",
        "\n",
        "\n",
        "for j in range(1, k):\n",
        "  print(j)\n",
        "  new_beam = {}\n",
        "  for reg in beam.keys():\n",
        "    area = literal_eval(reg)\n",
        "    for i in range(0, len(clusters)):\t\n",
        "      if str(i) in reg:\n",
        "        continue\n",
        "      new_area = copy.deepcopy(area)\n",
        "      new_area.append(i)\n",
        "      list.sort(new_area)\n",
        "      new_reg = str(new_area)\n",
        "      reg_consd = get_region(new_area)\n",
        "      delta = div(reg_consd, total)\n",
        "      t = sum(new_area)\n",
        "      vec = [t, delta]\n",
        "  \n",
        "      new_beam[new_reg] = vec\n",
        "      new_beam = sort_beam(new_beam)\n",
        "  final_beam = {}\n",
        "  cand = list(new_beam.keys())\n",
        "  cand_length = len(cand)\n",
        "  fraction = 1 / (beam_width - 1)\n",
        "  final_beam[cand[0]] = new_beam[cand[0]]\n",
        "  for m in range(1, beam_width):\n",
        "    ind = int(m * fraction * cand_length) - 1\n",
        "    print(ind)\n",
        "    final_beam[cand[ind]] = new_beam[cand[ind]]\n",
        "  final_beam[cand[cand_length-1]] = new_beam[cand[cand_length-1]]\n",
        "  beam = sort_beam(final_beam)\n",
        "  print(beam)\n",
        "        \n",
        "print(beam)\n",
        "print(len(beam))\n",
        "final_beam = {}\n",
        "cand = list(beam.keys())\n",
        "cand_length = len(cand)\n",
        "fraction = 1 / (tau - 1)\n",
        "final_beam[cand[0]] = new_beam[cand[0]]\n",
        "for m in range(1, tau):\n",
        "  ind = int(m * fraction * cand_length) - 1\n",
        "  #ind = m\n",
        "  print(ind)\n",
        "  final_beam[cand[ind]] = new_beam[cand[ind]]\n",
        "final_beam[cand[cand_length-1]] = new_beam[cand[cand_length-1]]\n",
        "beam = sort_beam(final_beam) #fair hotspots\n",
        "print(beam)\n",
        "print(len(beam))\n",
        "print(time.time() - start)"
      ],
      "metadata": {
        "id": "2G3KkCq99kHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#computing skyline for the purpose of evaluation\n",
        "\n",
        "skyline = {}\n",
        "all = []\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "m = len(clusters)\n",
        "for a in range(0, m):\n",
        "  for b in range(a+1, m):\n",
        "    for c in range(b+1, m):\n",
        "      for d in range (c+1, m):\n",
        "        for e in range(d+1, m):\n",
        "          ind = [a, b, c, d, e]\n",
        "          region = []\n",
        "          for i in range(0, 5):\n",
        "            region.extend(clusters[ind[i]])\n",
        "          delta = div(get_sum(region), total)\n",
        "          t = a+b+c+d+e\n",
        "          all.append([t, delta])\n",
        "          if (len(skyline) == 0):\n",
        "            skyline[str(ind)]=[t, delta]\n",
        "          else:\n",
        "            flag = False\n",
        "            replace = []\n",
        "            count = 0\n",
        "            for key, item in skyline.items():\n",
        "              if (item[0] >= t and item[1] >= delta):\n",
        "                flag = True\n",
        "                replace.append(key)\n",
        "              if ((t < item[0] and delta >= item[1]) or (t >= item[0] and delta < item[1])):\n",
        "                count += 1\n",
        "            if (count == len(skyline)):\n",
        "              flag = True\n",
        "            if (flag):\n",
        "              skyline [str(ind)] = [t, delta]\n",
        "              if (len(replace) != 0):\n",
        "                for r in replace:\n",
        "                  del(skyline[r])\n",
        "           \n",
        "print(skyline)\n",
        "print(len(skyline))\n",
        "print(all)\n",
        "print(time.time()-start)"
      ],
      "metadata": {
        "id": "xWBBokIp-Ntk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "all_data = scaler.fit_transform(all_clusters)\n"
      ],
      "metadata": {
        "id": "qKOi_dAj-aCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#all points\n",
        "all_clusters = np.asarray(all_clusters)\n",
        "plt.plot(all_clusters[:,0], all_clusters[:,1],'ro')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pHQUflr1-ewS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = np.asarray(all_data)\n",
        "plt.plot(all_data[:,1], all_data[:,0],'ro')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xFaMbmXp-h_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#skyline\n",
        "xa = []\n",
        "ya = []\n",
        "arr_sky = []\n",
        "for val in skyline.values():\n",
        "  xa.append(val[0])\n",
        "  ya.append(val[1])\n",
        "  arr_sky.append([val[0], val[1]])\n",
        "\n",
        "arr_sky = np.asarray(arr_sky)\n",
        "arr_sky_norm = scaler.transform(arr_sky)\n",
        "\n",
        "plt.plot(arr_sky_norm[:,1], arr_sky_norm[:,0],'bo')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pIMK-UGD-kDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print beam points\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x2 = []\n",
        "y2 = []\n",
        "arr_beam = []\n",
        "\n",
        "for item in beam.keys():\n",
        "  area = literal_eval(item)\n",
        "  x2.append(div(get_region(area), total))\n",
        "  y2.append(sum(area))\n",
        "  arr_beam.append([sum(area), div(get_region(area), total)])\n",
        "\n",
        "arr_beam = np.asarray(arr_beam)\n",
        "arr_beam_norm = scaler.transform(arr_beam)\n",
        "\n",
        "plt.plot(arr_beam_norm[:,1], arr_beam_norm[:,0],'go')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KPPYePnZ-mWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(all_data[:,1], all_data[:,0],'ro')\n",
        "jittered_y = arr_sky_norm[:,0] + 0.015 * np.random.rand(len(arr_sky_norm[:,0]))\n",
        "plt.plot(arr_sky_norm[:,1], jittered_y,'bo', alpha=0.7)\n",
        "plt.plot(arr_beam_norm[:,1], arr_beam_norm[:,0],'go')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RqSqR-dE-oWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gold standard\n",
        "beam_width = len(beam)\n",
        "fraction = 1 / (beam_width - 1)\n",
        "gold_standard = [arr_sky_norm[0]]\n",
        "for m in range(1, beam_width):\n",
        "  ind = int(m * fraction * len(arr_sky_norm)) - 1\n",
        "  #ind = m\n",
        "  gold_standard.append(arr_sky_norm[ind])\n",
        "\n",
        "print(len(arr_sky_norm))\n",
        "print(gold_standard)\n",
        "print(arr_beam_norm)\n",
        "gold_standard = np.asarray(gold_standard)\n",
        "print(gold_standard)\n",
        "\n",
        "#plt.plot(arr_sky_norm[:,0], arr_sky_norm[:,1],'bo')\n",
        "plt.plot(gold_standard[:,0], gold_standard[:,1],'yo')\n",
        "plt.show()\n",
        "plt.plot(arr_beam_norm[:,0], arr_beam_norm[:,1],'go')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1bjzUFJt-qW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jittered_y = arr_beam_norm[:,0] + 0.018 * np.random.rand(len(arr_beam_norm[:,0]))\n",
        "jittered_y_gold = gold_standard[:,0] - 0.02 * np.random.rand(len(gold_standard[:,0]))\n",
        "plt.plot(all_data[:,1], all_data[:,0],'ro',alpha=0.8, markersize=3)\n",
        "plt.plot(gold_standard[:,1], jittered_y_gold,'yo', markersize=9, mec='black')\n",
        "plt.plot(arr_beam_norm[:,1], jittered_y,'go', alpha=0.8, markersize=9, mec='black')\n",
        "plt.xlim(-0.005,0.125)\n",
        "plt.ylim(-0.05, 0.8)\n",
        "plt.xlabel('Deviation')\n",
        "plt.ylabel('Sum of Ranks')\n",
        "plt.tick_params(\n",
        "    axis='both',         \n",
        "    which='both',          \n",
        "    bottom=False,   \n",
        "    top=False,\n",
        "    left=False,\n",
        "    right=False,\n",
        "    labelbottom=False,\n",
        "    labelleft=False) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s9bk8hn_-t5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#direct comparison\n",
        "import math\n",
        "\n",
        "dc = 0\n",
        "for i in range(0, len(beam)):\n",
        "  cur_dist = math.sqrt((arr_beam_norm[i,0]-gold_standard[i,0])**2 \n",
        "                       + (arr_beam_norm[i,1]-gold_standard[i,1])**2)\n",
        "  dc += cur_dist\n",
        "print(dc)"
      ],
      "metadata": {
        "id": "kr2eHjSy-0Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#coverage\n",
        "\n",
        "n = len(all_data)\n",
        "print(n)\n",
        "\n",
        "#coverage-beam\n",
        "def coverage(candidate, corpus):\n",
        "  n = len(corpus)\n",
        "  count = 0.0\n",
        "  for i in range(0, n):\n",
        "    for j in range(0, len(candidate)):\n",
        "      x = corpus[i]\n",
        "      y = candidate[j]\n",
        "      if (y[0] < x[0] and y[1] < x[1]):\n",
        "        count += 1\n",
        "        break\n",
        "  return count / n\n",
        "\n",
        "print(coverage(arr_beam_norm, all_data))\n",
        "    "
      ],
      "metadata": {
        "id": "c34z6SqX-2f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#diversity\n",
        "\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "#dist1 = euclidean_distances(gold_standard, gold_standard)\n",
        "dist2 = euclidean_distances(arr_beam_norm, arr_beam_norm)\n",
        "#print(dist1)\n",
        "print(dist2)\n",
        "\n",
        "#average1 = dist1[np.nonzero(dist1)].min()\n",
        "average2 = dist2[np.nonzero(dist2)].min()\n",
        "print(average2)\n",
        "#print(average1)"
      ],
      "metadata": {
        "id": "ypZcBgKI-9Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "055ymvIL--7x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}